import cv2
import numpy as np
from pathlib import Path
import os
import subprocess
from django.conf import settings

class VideoDetector:
    """ë™ì˜ìƒ ë° ì´ë¯¸ì§€ ê°ì²´ ê°ì§€ ì²˜ë¦¬ (YOLO ê¸°ë°˜)"""
    
    def __init__(self, model):
        self.model = model
        self.model_type = model.model_type
        self.yolo_model = None
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        if self.model_type == 'yolo':
            self.load_yolo_model()
    
    def load_yolo_model(self):
        """YOLO ëª¨ë¸ ë¡œë“œ ë¡œì§ (ê¸°ì¡´ ìœ ì§€)"""
        try:
            from ultralytics import YOLO
            model_path = self.model.get_model_path()
            if not model_path:
                raise ValueError("ëª¨ë¸ íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            print(f"ğŸ”„ YOLO ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}")
            self.yolo_model = YOLO(model_path)
            print(f"âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def detect_frame(self, frame):
        """ë‹¨ì¼ í”„ë ˆì„ ê°ì§€ ë¶„ê¸°"""
        if self.model_type == 'yolo':
            return self.detect_yolo(frame)
        return []

    def detect_yolo(self, frame):
        """YOLO ê°ì²´ ê°ì§€ ë¡œì§ (ì±„ë„ ì˜¤ë¥˜ ìˆ˜ì • í¬í•¨)"""
        if not self.yolo_model:
            return []
        
        try:
            # â­ [ìˆ˜ì •] 4ì±„ë„(RGBA) ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¬ ê²½ìš° 3ì±„ë„(BGR)ë¡œ ë³€í™˜
            if len(frame.shape) == 3 and frame.shape[2] == 4:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)

            results = self.yolo_model(frame, verbose=False)
            detections = []
            
            for result in results:
                for box in result.boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = float(box.conf[0])
                    class_id = int(box.cls[0])
                    label = self.yolo_model.names[class_id]
                    
                    conf_threshold = self.model.config.get('conf_threshold', 0.25)
                    if confidence >= conf_threshold:
                        detections.append({
                            'label': label,
                            'confidence': confidence,
                            'bbox': [int(x1), int(y1), int(x2-x1), int(y2-y1)],
                        })
            return detections
        except Exception as e:
            print(f"âš ï¸  YOLO ê°ì§€ ì˜¤ë¥˜: {e}")
            return []

    def process_video(self, input_path, output_path, progress_callback=None):
        """ë™ì˜ìƒ/ì´ë¯¸ì§€ì— ê°ì§€ ëª¨ë¸ ì ìš© ë° ê²°ê³¼ ì €ì¥"""
        print(f"\n{'='*60}\nğŸ” ê°ì§€ ì²˜ë¦¬ ì‹œì‘\n{'='*60}")
        
        # 1. ë¯¸ë””ì–´ íƒ€ì… íŒë³„
        is_image = input_path.lower().endswith(('.png', '.jpg', '.jpeg', '.webp'))

        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            raise ValueError(f"íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        
        # 2. ë¯¸ë””ì–´ ì •ë³´ ì¶”ì¶œ (ì¤‘ìš”: VideoWriter ìƒì„±ë³´ë‹¤ ë¨¼ì € ì‹¤í–‰)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        if is_image:
            fps = 1
            total_frames = 1
        else:
            fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        print(f"ğŸ–¼ï¸  í•´ìƒë„: {width}x{height} | FPS: {fps} | ì´ í”„ë ˆì„: {total_frames}")

        # 3. ì¶œë ¥ ì„¤ì • ë¶„ê¸°
        out = None
        temp_output = output_path
        annotated_frame = None 

        if not is_image:
            # ë™ì˜ìƒì¼ ë•Œë§Œ ì„ì‹œ íŒŒì¼(temp_) ë° VideoWriter ìƒì„±
            temp_output = str(Path(output_path).parent / f'temp_{Path(output_path).name}')
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(temp_output, fourcc, fps, (width, height))
            if not out.isOpened():
                cap.release()
                raise ValueError("ì¶œë ¥ VideoWriter ìƒì„± ì‹¤íŒ¨")

        all_detections = []
        detection_summary = {}
        total_detections_count = 0
        frame_count = 0

        try:
            print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘...")
            while True:
                ret, frame = cap.read()
                if not ret: break
                
                # ê°ì§€ ìˆ˜í–‰ ë° ê·¸ë¦¬ê¸°
                detections = self.detect_frame(frame)
                annotated_frame = self.draw_detections(frame, detections)
                
                if not is_image and out:
                    out.write(annotated_frame)
                
                if detections:
                    all_detections.append({'frame': frame_count, 'detections': detections})
                    total_detections_count += len(detections)
                    for det in detections:
                        label = det['label']
                        detection_summary[label] = detection_summary.get(label, 0) + 1
                
                frame_count += 1
                if progress_callback and frame_count % 10 == 0:
                    progress = int((frame_count / total_frames) * 80)
                    progress_callback(frame_count, total_frames, progress)

        finally:
            cap.release()
            if out: out.release()

        # 4. ìµœì¢… ì €ì¥ ë° ì¸ì½”ë”©
        if is_image:
            if annotated_frame is not None:
                cv2.imwrite(output_path, annotated_frame)
                print(f"âœ… ì´ë¯¸ì§€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            ffmpeg_success = True
        else:
            print(f"\nğŸ¬ ë™ì˜ìƒ ì¬ì¸ì½”ë”© ì‹œì‘...")
            if progress_callback: progress_callback(frame_count, total_frames, 85)
            ffmpeg_success = self.reencode_with_ffmpeg(temp_output, output_path)
            
            if ffmpeg_success and os.path.exists(temp_output):
                os.remove(temp_output)
            elif not ffmpeg_success:
                print(f"âš ï¸  ffmpeg ì‹¤íŒ¨ - ì›ë³¸ íŒŒì¼ ì´ë™ ì‹œë„")
                if os.path.exists(output_path): os.remove(output_path)
                os.rename(temp_output, output_path)

        if progress_callback: progress_callback(frame_count, total_frames, 100)

        return {
            'detections': all_detections,
            'total_detections': total_detections_count,
            'summary': detection_summary,
        }

    def draw_detections(self, frame, detections):
        """ê°ì§€ ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°"""
        result = frame.copy()
        for det in detections:
            x, y, w, h = det['bbox']
            label = det['label']
            conf = det['confidence']
            color = self.get_color_for_label(label)
            cv2.rectangle(result, (x, y), (x+w, y+h), color, 2)
            text = f"{label} {conf:.2f}"
            cv2.putText(result, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        return result

    def get_color_for_label(self, label):
        """ë¼ë²¨ë³„ ìƒ‰ìƒ ì§€ì •"""
        hash_val = hash(label)
        return (hash_val & 0xFF, (hash_val >> 8) & 0xFF, (hash_val >> 16) & 0xFF)

    def reencode_with_ffmpeg(self, input_path, output_path):
        """ffmpeg ì¸ì½”ë”© ë¡œì§ (ê¸°ì¡´ ìœ ì§€)"""
        import shutil
        ffmpeg_path = shutil.which('ffmpeg') or r'C:\ffmpeg\bin\ffmpeg.exe'
        if not os.path.exists(ffmpeg_path): return False
        
        try:
            cmd = [ffmpeg_path, '-i', str(input_path), '-c:v', 'libx264', '-preset', 'fast', '-y', str(output_path)]
            subprocess.run(cmd, capture_output=True, text=True, timeout=1800)
            return os.path.exists(output_path)
        except:
            return False